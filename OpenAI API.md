# Основы

> OpenAI API может применяться к любым задачам, которые подразумевают понимание или создание текстов, кода или изображений.
> *— Официальная документация*

## Термины

**Модель (Model)** — в области ML так называют любой алгоритм или систему, которая используется для конкретных целей. В OpenAI этот термин обычно подразумевает системы GPT, которые обучены на текстовых данных для генерации и понимания естественного языка. GPT расшифровывается Generative Pre-trained Transformer, где Transformer — это определённый подход глубокого обучения.

**Запросы (Prompts)** — текстовые инструкции или примеры, которые "программируют" модель.

**Завершение (Completion)** — содержание ответа в ответ на запрос.

**Токены (Tokens)** — единица ==текста==, с которой работает модель. Представляет из себя короткое слово или часть длинного слова. Часто начинается с пробела. Приблизительно считается по формуле 1 токен = 4 символа = 0.75 слова.

# Аутентификация
По ключу. Генерируется тут: https://platform.openai.com/account/api-keys

# Модели
|Название|Описание|
|-|-|
| GPT-3 | Набор моделей для текста и кода |
| GPT-4 | Улучшенный набор моделей для текста и кода |
| DALL-E | Генерирует и редактирует изображения|
| Whisper | Преобразует речь в текст |

Полный список тут: https://platform.openai.com/docs/models

# Работа с текстом

Называется "Completion" и осуществляется с помощью POST-запросов на Chat API:
- Text completion (дополняет или генерирует текст) — [docs](https://platform.openai.com/docs/api-reference/completions/create)
- Chat completion (отвечает на реплики беседы) — [docs](https://platform.openai.com/docs/api-reference/chat/create)

У запроса есть разные параметры:
- Количество [токенов](https://platform.openai.com/tokenizer) — единиц обрабатываемого текста. ≈ 4 символам или 0.75 слова 
- Суффикс для добавления в конец запроса
- Степень детерминированности (`temperature` или `top_p`) — чем больше, тем больше ответы на одинаковые запросы будут отличаться.
и другие.

> [!NOTE] Chat APIs по умолчанию __недетерминированные__, то есть без возможности предсказать выдаваемый ими результат.

В теле запроса обязательно указывается текущая модель (`model`) и сообщение (`prompt` или `messages`):

```js
fetch(BASE_URL, {
		method: 'POST',
		headers: {
			Authorization: `Bearer ${API_KEY}`,
			'Content-Type': 'application/json'
		},
		body: JSON.stringify({
			model: 'gpt-3.5-turbo',
			max_tokens: 7,
			temperature: 0,
			prompt: 'hello, how are you?', // или
			messages: [
				{role: 'user', content: 'hello, how are you?'}
			]
		})
})
```

## Запросы

Качественный промпт — залог того, что модель ответит наилучшим образом. Вот основной алгоритм:

1. Cоставь запрос
2. Добавь проверенные данные (напр. примеры)
3. Проверь настройки

Чтобы улучшить навык писать качественные промпты, можно пройти [курс от OpenAI](https://learn.deeplearning.ai/chatgpt-prompt-eng) или посмотреть мой конспект [[ChatGPT Prompt Engineering for Developers]]

# Внешние ресурсы
Документация — https://platform.openai.com/docs/introduction/overview